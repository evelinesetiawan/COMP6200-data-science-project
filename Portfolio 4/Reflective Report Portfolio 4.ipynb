{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ee7e438",
   "metadata": {},
   "source": [
    "# Analysis of Obesity Level Based on Eating Habits and Physical Conditions\n",
    "\n",
    "Portfolio 4 is an analysis of the Obesity dataset that were divided into levels on Eating Habits and Physical Conditions. The analysis will mainly examine factors that can influence the status of obesity level for each individual. The dataset for estimation of obesity levels based on eating habits and physical condition in individuals from Colombia, Peru, and Mexico. The objective of this analysis is to know the factors that contribute to the obesity level status the most and analyze the cluster based on the obesity level.\n",
    "\n",
    "The dataset where obtained from this website: [Obesity Risk Prediction Dataset](https://www.kaggle.com/datasets/ikjotsingh221/obesity-risk-prediction-cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf6d7c",
   "metadata": {},
   "source": [
    "**Data Science Unit & Future Interest**\n",
    "\n",
    "From the beginning of the units, we were taught many data science tools and their implementation in real cases about how to prepare the data, tools selection, and finally the conclusion and analysis of the data. We studied Jupyter Notebook for the data science unit and I found it interesting. Further, the simple interface is quite suitable for us, especially as someone who does not have a data science background.\n",
    "\n",
    "After I finished Portfolio 4, my interest in doing more analysis of data is increasing since there is a huge amount of datasets that has not been analyzed, and even though they already have the analysis regarding the dataset, there are some tools that I have been studying but has not implemented yet for those project, which I want to try in the future. \n",
    "\n",
    "**Progress of Portfolio 4**\n",
    "\n",
    "I chose this dataset because of the completeness of its features or factors that influence the level of someone’s obesity level, which is not only impacted by eating habits but also based on an individual’s lifestyle.\n",
    "\n",
    "The next step is to choose the target variable I want to observe. First, I looked at the dataset and categorized each variable between lifestyle factors and physical condition. After that, we can draw conclusions that all these variables lead to obesity levels. Here below are the data science tools I used to analyze Portfolio 4.\n",
    "\n",
    "For this Portfolio, I chose 3 machine learning models: KMeans Clustering, Logistic Regression, and RFE Analysis. Using KMeans clustering for this data before doing any regression is to display distinct lifestyle clusters within the dataset and their correspondence to various obesity levels. In the context of obesity, logistic regression would be used if the target variable is categorical, such as predicting whether an individual is obese or not based on a binary classification. Because the target variable we are using in this model is **\"NObeyesdad\"** is categorical data, so logistic regression is chosen for the analysis of this dataset. Lastly, I decided to use RFE analysis to search among the variables observed, which factors has the most impact on obesity levels.\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "The correlation result of this dataset shows that Weight, Consumption of food between meals, overweight family history, and age are the factors that have a strong correlation to influence obesity levels. However, after I ran the RFE analysis, it turned out that Weight, Height, Gender, and frequency of eating vegetables are the factors that have a heavier impact on obesity levels. The outcome for this is quite predictable, especially for weight and height which are directly connected to the obesity levels which obesity levels categorized by body mass index calculation.\n",
    "\n",
    "**Discussion**\n",
    "\n",
    "When I decided to use this dataset, I ran a correlation between variables. Subsequent to the result, I planned to observe variables that have a stronger correlation with a value close to 1 or -1, these variables with the strongest correlation are : Weight, CAEC, family_history_with_overweight, and Age. Nonetheless, I changed by observing all variables. I decided to use all variables except 'NObeyesdad' since the model performs better than using 4 variables that have a strong correlation with the target variable. When using fewer features can sometimes help in reducing overfitting (where the model learns the noise in the training data rather than the actual signal), leading to better generalization on unseen data. Nevertheless, in this case, seems like using only the four features might be leading to underfitting, where the model is too simple to capture the complexity of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92907ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
